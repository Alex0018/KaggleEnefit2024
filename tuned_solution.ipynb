{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "\n",
    "import gc\n",
    "\n",
    "import math\n",
    "\n",
    "from xgboost import XGBRegressor as XGB\n",
    "from lightgbm import LGBMRegressor as LGB\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "SEED=42\n",
    "\n",
    "from src.correlations import *\n",
    "from src.features_train import get_features\n",
    "\n",
    "from src.styles import *\n",
    "set_styles()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitKFold:\n",
    "    def __init__(self, n_splits=3, test_len=3*24*30):\n",
    "        self.n_splits = n_splits\n",
    "        self.test_len = test_len\n",
    "        \n",
    "    def split(self, X):        \n",
    "        for fold in range(self.n_splits):\n",
    "            offset = X['time_id'].max() - (self.n_splits - fold) * self.test_len\n",
    "            idx_train = X.loc[X['time_id'] < offset].index\n",
    "            idx_test = X.loc[(X['time_id'] >= offset) & (X['time_id'] < offset + self.test_len)].index            \n",
    "            yield idx_train, idx_test\n",
    "            \n",
    "    def get_n_splits(self, X, y):\n",
    "        return self.n_splits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def eval(X, Y, splitter, model):\n",
    "    scores = []\n",
    "    \n",
    "    df_oof = pd.DataFrame()\n",
    "    \n",
    "    for fold, (idx_train, idx_val) in enumerate(splitter.split(X)):\n",
    "        X_train = X.loc[idx_train].dropna()\n",
    "        Y_train = Y.loc[X_train.index]\n",
    "        Y_val = Y.loc[idx_val].dropna()\n",
    "        X_val = X.loc[Y_val.index]\n",
    "        \n",
    "        model.fit(X_train, Y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        score = mae(Y_val, preds)\n",
    "        scores.append(score)\n",
    "        \n",
    "        df = X_val[['time_id', 'is_consumption', 'is_business', 'product_type', 'county']]\n",
    "        df['preds'] = preds\n",
    "        df['target'] = Y_val\n",
    "        df_oof = pd.concat([df_oof, df], axis=0)\n",
    "        \n",
    "    return np.array(scores), df_oof\n",
    "\n",
    "\n",
    "def score_cv(X, Y, factor, splitter, model):\n",
    "    scores = []\n",
    "    \n",
    "    df_oof = pd.DataFrame()\n",
    "    \n",
    "    for fold, (idx_train, idx_val) in enumerate(splitter.split(X)):\n",
    "        X_train = X.loc[idx_train].dropna()\n",
    "        Y_train = Y.loc[X_train.index]\n",
    "        Y_val = Y.loc[idx_val].dropna()\n",
    "        X_val = X.loc[Y_val.index]\n",
    "        factor_val = factor.loc[Y_val.index]\n",
    "        \n",
    "        model.fit(X_train, Y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        score = mae(Y_val*factor_val, preds*factor_val)\n",
    "        scores.append(score)\n",
    "        \n",
    "        df = X_val[['time_id', 'is_consumption', 'is_business', 'product_type', 'county']]\n",
    "        df['preds'] = preds*factor_val\n",
    "        df['target'] = Y_val*factor_val\n",
    "        df_oof = pd.concat([df_oof, df], axis=0)\n",
    "        \n",
    "    return np.array(scores), df_oof\n",
    "\n",
    "\n",
    "def score_dif(X, Y, A, splitter, model):\n",
    "    scores = []\n",
    "    \n",
    "    df_oof = pd.DataFrame()\n",
    "    \n",
    "    for fold, (idx_train, idx_val) in enumerate(splitter.split(X)):\n",
    "        X_train = X.loc[idx_train].dropna()\n",
    "        Y_train = Y.loc[X_train.index]\n",
    "        Y_val = Y.loc[idx_val].dropna()\n",
    "        X_val = X.loc[Y_val.index]\n",
    "        a = A.loc[Y_val.index]\n",
    "        \n",
    "        model.fit(X_train, Y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        score = mae((Y_val+a)*b, (preds+a)*b)\n",
    "        scores.append(score)\n",
    "        \n",
    "        df = X_val[['time_id', 'is_consumption', 'is_business', 'product_type', 'county']]\n",
    "        df['preds'] = preds+a\n",
    "        df['target'] = Y_val+a\n",
    "        df_oof = pd.concat([df_oof, df], axis=0)\n",
    "        \n",
    "    return np.array(scores), df_oof\n",
    "\n",
    "\n",
    "def print_mae_sep(df_oof):\n",
    "    for c in [0,1]:\n",
    "        for b in [0,1]:\n",
    "            df = df_oof.query(f'(is_consumption=={c}) & (is_business=={b})')    \n",
    "            print(c, b, end='       ')\n",
    "            for fold in range(4):\n",
    "                offset = df['time_id'].max() - (4 - fold) * 3*24*30\n",
    "                dd = df.loc[(df['time_id'] >= offset) & (df['time_id'] < offset + 3*24*30)]\n",
    "                print(f\"{mae(dd['target'], dd['preds']):.3f}\".rjust(10), end='    ')\n",
    "            print(f\"        {mae(df['target'], df['preds']):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 78.1 ms\n",
      "Wall time: 96.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_weather_station_to_county_mapping = pd.read_csv('data/weather_station_to_county_mapping.csv').dropna()\n",
    "    \n",
    "df_weather_station_to_county_mapping['lat_lon'] = df_weather_station_to_county_mapping.apply(lambda row: \\\n",
    "                                                     f'{row[\"latitude\"]:.1f}_{row[\"longitude\"]:.1f}', axis=1)\n",
    "dict_county = df_weather_station_to_county_mapping[['lat_lon', 'county']].set_index('lat_lon').to_dict()['county']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 20s\n",
      "Wall time: 1min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_gas_prices = pd.read_csv('data/gas_prices.csv')\n",
    "df_electricity_prices = pd.read_csv('data/electricity_prices.csv')\n",
    "df_client = pd.read_csv('data/client.csv')\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_forecast_weather = pd.read_csv('data/forecast_weather.csv')\n",
    "df_historical_weather = pd.read_csv('data/historical_weather.csv')\n",
    "df = get_features(df_train, df_client, df_gas_prices, df_electricity_prices, df_forecast_weather, df_historical_weather, dict_county)\n",
    "del df_forecast_weather, df_historical_weather\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0           40.772        16.896         6.375        48.048            27.816\n",
      "0 1           42.241        14.044         4.858        55.879            29.135\n",
      "1 0            8.096        18.327        31.504        24.763            20.701\n",
      "1 1           99.069        89.110        95.912        92.817            94.186\n",
      "CPU times: total: 43min 41s\n",
      "Wall time: 25min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = df.query('is_consumption==0')\n",
    "Y = X.pop('target') / X['installed_capacity']\n",
    "\n",
    "splitter = SplitKFold(n_splits=4)\n",
    "\n",
    "lgb_best_params_0 = {'device': 'gpu',\n",
    " 'max_depth': 10,\n",
    " 'objective': 'mae',\n",
    " 'reg_alpha': 27.925287981085468,\n",
    " 'subsample': 0.5976031697826543,\n",
    " 'reg_lambda': 22.884627910174338,\n",
    " 'n_estimators': 588,\n",
    " 'random_state': 42,\n",
    " 'learning_rate': 0.016017459248525004,\n",
    " 'colsample_bytree': 0.565707682564599}\n",
    "model_0 = LGB(verbose=-100, **lgb_best_params_0, num_leaves=2**lgb_best_params_0['max_depth'] - 1)\n",
    "scores_0, df_oof_dual_0_tuned = score_cv(X, Y, X['installed_capacity'], splitter, model_0)\n",
    "\n",
    "lgb_best_params_1 = {'device': 'gpu',\n",
    " 'max_depth': 10,\n",
    " 'objective': 'mae',\n",
    " 'reg_alpha': 2.683818422446349,\n",
    " 'subsample': 0.925323652336999,\n",
    " 'reg_lambda': 11.286432355402798,\n",
    " 'n_estimators': 730,\n",
    " 'random_state': 42,\n",
    " 'learning_rate': 0.044074000160673456,\n",
    " 'colsample_bytree': 0.9929981807318676}\n",
    "X = df.query('is_consumption==1')\n",
    "Y = X.pop('target') \n",
    "\n",
    "splitter = SplitKFold(n_splits=4)\n",
    "model_1 = LGB(verbose=-100, **lgb_best_params_1, num_leaves=2**lgb_best_params_1['max_depth'] - 1)\n",
    "scores_1, df_oof_dual_1_tuned = eval(X, Y, splitter, model_1)\n",
    "\n",
    "df_oof_dual_tuned = pd.concat([df_oof_dual_0_tuned, df_oof_dual_1_tuned], axis=0)\n",
    "print_mae_sep(df_oof_dual_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new_target = target - target_lag_48h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0           43.630        20.250         8.486        82.804            38.452\n",
      "0 1           51.167        17.345         5.453        69.986            35.837\n",
      "1 0            8.372        17.955        32.984        26.912            21.576\n",
      "1 1           93.143        84.839        95.275        96.603            92.402\n",
      "CPU times: total: 7min 25s\n",
      "Wall time: 4min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "splitter = SplitKFold(n_splits=4)\n",
    "model = LGB(random_state=SEED, n_estimators=500, max_depth=5, num_leaves=31, objective='mae', device='gpu', verbose=-100)\n",
    "\n",
    "X = df.query('is_consumption==0')\n",
    "Y = X.pop('target') - X['target_48']\n",
    "scores_0, df_oof_dual_0_dif = score_dif(X, Y, X['target_48'], splitter, model)\n",
    "\n",
    "\n",
    "X = df.query('is_consumption==1')\n",
    "Y = X.pop('target') - X['target_48']\n",
    "scores_1, df_oof_dual_1_dif = score_dif(X, Y, X['target_48'], splitter, model)\n",
    "\n",
    "df_dual_diff = pd.concat([df_oof_dual_0_dif, df_oof_dual_1_dif], axis=0)\n",
    "print_mae_sep(df_dual_diff) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mean of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0           35.935        17.685         6.969        59.565            29.798\n",
      "0 1           42.909        14.889         4.830        56.806            29.738\n",
      "1 0            7.690        17.106        29.829        24.131            19.711\n",
      "1 1           90.988        80.976        86.503        88.891            86.793\n"
     ]
    }
   ],
   "source": [
    "df_oof_dual_mean = 0.5 * (df_oof_dual_tuned + df_dual_diff)\n",
    "print_mae_sep(df_oof_dual_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-model solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 27min 11s\n",
      "Wall time: 16min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_oofs_tuned = []\n",
    "splitter = SplitKFold(n_splits=4)\n",
    "\n",
    "lgb_params = [\n",
    "    {'device': 'gpu',\n",
    " 'max_depth': 7,\n",
    " 'objective': 'mae',\n",
    " 'reg_alpha': 84.8348443946615,\n",
    " 'subsample': 0.7457382126409933,\n",
    " 'reg_lambda': 54.981855156064974,\n",
    " 'n_estimators': 986,\n",
    " 'random_state': 42,\n",
    " 'learning_rate': 0.025958201025540827,\n",
    " 'colsample_bytree': 0.2316453494439351},\n",
    "    {'device': 'gpu',\n",
    " 'max_depth': 9,\n",
    " 'objective': 'mae',\n",
    " 'reg_alpha': 0.8552097909171774,\n",
    " 'subsample': 0.6395685038517376,\n",
    " 'reg_lambda': 12.912361932527617,\n",
    " 'n_estimators': 587,\n",
    " 'random_state': 42,\n",
    " 'learning_rate': 0.016510018898018324,\n",
    " 'colsample_bytree': 0.7613937918848874},\n",
    "    {'device': 'gpu',\n",
    " 'max_depth': 4,\n",
    " 'objective': 'mae',\n",
    " 'reg_alpha': 7.789969529711993,\n",
    " 'subsample': 0.6788618540001061,\n",
    " 'reg_lambda': 95.04678210912456,\n",
    " 'n_estimators': 717,\n",
    " 'random_state': 42,\n",
    " 'learning_rate': 0.10662803911937269,\n",
    " 'colsample_bytree': 0.5440716377164676},\n",
    "    {'device': 'gpu',\n",
    " 'max_depth': 7,\n",
    " 'objective': 'mae',\n",
    " 'reg_alpha': 32.02008292675173,\n",
    " 'subsample': 0.9464933926786616,\n",
    " 'reg_lambda': 13.836202707048916,\n",
    " 'n_estimators': 758,\n",
    " 'random_state': 42,\n",
    " 'learning_rate': 0.03841847402871685,\n",
    " 'colsample_bytree': 0.9949734593585886 }\n",
    "]\n",
    "\n",
    "for c in [0,1]:\n",
    "    for b in [0,1]:\n",
    "\n",
    "        X = df.query(f'(is_consumption=={c}) & (is_business=={b})')\n",
    "        params = lgb_params[c*2+b]\n",
    "        \n",
    "        if not ((c==1) and (b==1)):\n",
    "            Y = X.pop('target') / X['installed_capacity'] \n",
    "            scores, df_oof = score_cv(X, Y, X['installed_capacity'], splitter, LGB(verbose=-100, **params, num_leaves=2**params['max_depth'] - 1))\n",
    "            df_oofs_tuned.append(df_oof)\n",
    "        else:\n",
    "            Y = X.pop('target') \n",
    "            scores, df_oof = eval(X, Y, splitter, LGB(verbose=-100, **params, num_leaves=2**params['max_depth'] - 1))\n",
    "            df_oofs_tuned.append(df_oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0           35.369        16.694         6.652        49.308            26.806\n",
      "0 1           44.934        14.027         4.956        56.596            30.002\n",
      "1 0           11.937        15.221        22.132        21.668            17.737\n",
      "1 1          100.895        86.982       101.835        94.672            96.029\n"
     ]
    }
   ],
   "source": [
    "df_oof_quad_tuned = pd.concat(df_oofs_tuned, axis=0)\n",
    "print_mae_sep(df_oof_quad_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
